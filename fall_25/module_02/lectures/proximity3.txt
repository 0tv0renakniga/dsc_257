(bright music) - Welcome back. A lot of unsupervised learning is about finding good representations of data. So let's talk a little bit more about this. There's a quote that I like from the philosopher Herb Simon in which he says that, "Solving a problem simply means representing it so as to make the solution transparent." In unsupervised learning, what we want are representations of data in which the structure of the data just pops out. And indeed, much of the success of machine learning in fields like vision, speech, text has come from finding progressively better and better ways to represent data from these domains. In natural language processing, for example, there's been a long history of different representations of text, starting with the very primitive bag of words model, to latent semantic indexing, Brown clustering, topic models, and more recently, representations that are used in neural nets and produced by neural nets. So let's, by way of example, look at one of these. Let's look at Word2Vec. Now, Word2Vec is a representation of English words. So each word is associated with a 300-dimensional vector. And the idea is that words that are similar in meaning should have vectors that are close together. In this way, the vectors capture the semantic structure of words, okay? So for example, let's say that this is the vector for the word happy. Then what we would expect is that the word content, for example, has a vector that's fairly close to this. Maybe this is the vector for the word content. Meanwhile, the vector for miserable would be far away, so maybe this is the vector for miserable. Using these vectors to represent words has just made a huge difference in natural language processing. It's been a tremendous boon to have this representation that captures the semantic structure of words. A similar progression has been seen in computer vision. There's been all these different representations, and in fact, we'll be talking about several of these in lecture and investigating some of them in our programming projects. These days, a very good way to represent images is to take some pre-trained convolutional neural net, feed the image in on one side, and then use the values at one of the later layers as a representation of the image. And in this image space, in this vector space that we get, even simple distance functions like L2 distance can work quite well, whereas L2 distance is often very poor in the raw pixel space, in the space of the original image. There's been a similar push in other fields, in speech, music, DNA sequences, protein sequences, a push to find good representations. Later on in the course, we'll talk about trying to automatically find good representations of data, an enterprise known as representation learning. 