(soft music) (air wooshing) - Okay. Hello everybody. Now in unsupervised learning, we don't have any labels, we just have the data space. And as a result, the geometry of that space takes on central importance. Now, the geometry includes any kind of distance or similarity function that we choose to associate with the data space. Let's see how this plays out in a simple example. So let's talk a little bit about the Mars Curiosity Rover. So the rover has a bunch of instruments on it and one of them is called ChemCam. Now, the purpose of this instrument is to help scientists understand the geology of Mars. So ChemCam has a laser and it can point this laser at a rock and blast the rock. And this gives off light. And by looking at the wavelengths of the light, one can get an idea of the chemical composition of the rock. Okay, so this picture over here shows an example of a wavelength spectrum generated by ChemCam. It's an example of the kind of observations that the ChemCam returns. On the horizontal axis over here, we have different wavelengths, and you can see that the wavelengths run from 240 to over 800. And on the vertical axis we have different intensities. Okay. So, for each element there are characteristic wavelengths at which they appear. So for instance, this spike over here and this spike over here are indicative of the presence of sodium. Now, given this kind of data, one natural question is, once we see an observation like this, is it something familiar? Is this a kind of rock that we've seen before or is it something new, something that warrants further study? How would we answer this question? Well, let's start by phrasing it a little bit more abstractly. This is essentially a novelty detection problem. So we have observations, X one, X two, XN and let's say that these are the past observations made by ChemCam, okay? And they lie in some space that we will generically call script X. So these are previous observations. Now we make a new observation, little x. and what we are wondering is, is little x something completely new or is it something familiar? One rather simple way to solve this problem is by using proximity search, that is to say nearest neighbor search. What we can do is to choose a distance function on this observation space, script X. And now we store all the observations we've seen. So we remember X one through XN. And when a new observation X arises, what we do is we find its nearest neighbor amongst the observations that we've stored. Okay? In other words, we look at the distance from X to its nearest neighbor amongst past observations. If this distance is small, then X is something familiar. We've seen things like X before but if this distance is large, then X is something new. Okay? So this is a nice simple approach to solving a novelty detection problem. Now, in order to realize this approach, all we have to do is to precisely specify what this data space is. What is this space script X? And we also need to pin down a distance function on this space. Okay? So in the case of ChemCam, what are these? So here again, is an example of an observation returned by ChemCam. It's a wavelength spectrum, okay? In spreadsheet form, it looks like this. Okay? So over here are the different wavelengths that we saw on the horizontal axis. That is to say these numbers along here. And this column over here shows the intensities observed at these different wavelengths after one shot of the laser. And it turns out that there are 6,144 wavelengths, okay? So the size of this column is 6,144. And so what we could do is to represent this observation, that is to say this column over here, by a vector with 6,144 entries, literally just copy over that column. If we do that, then the data space, script X, consists of vectors with 6,144 entries and we would write it like that. Now, in this particular case, the numbers are never negative. They're all either zero or positive. And if we wanted to emphasize that we could write a little plus sign over here, okay? Or not, we could leave it off if we like. Okay? So that's a way of emphasizing that we have non-negative values. Okay? So this is script X. What about the distance function? So we need to choose a distance function in order to do proximity search. And our data, we've said, consists of vectors in 6,144 dimensions, okay? Perhaps the simplest distance function we can think of is just physical distance which is Euclidean distance or L two distance. Okay? So let's say we have two vectors, X and Z. And let's say they're in M dimensional space. So for example, in our case, M is 6,144. Okay? And so the vector X has got this many entries entries X one, X two, all the way to XM. And likewise, Z has got entries Z one, Z two all the way to ZM. The Euclidean distance between these two vectors, we'll write like this. And to compute this, what we do is that we look at each of the coordinates, okay? So we look at coordinate I as I runs from one through M. Okay? So I indexes the coordinate. I runs from one through M. And each time we're looking at a particular coordinate, we look at the difference between the two vectors along that coordinate. So we look at XI minus ZI, we square that difference, and now we add up all these values. Okay? So we add up the square differences along all of the coordinates. And then when we've done that, we take the square root of the whole thing and this is Euclidean distance. Okay? So one way to solve our novelty detection problem is to identify the observations with vectors with 6,144 dimensions. That is to say, that the input space, script X is R to the 6144. And to say that our distance function is Euclidean. But that's just one option. And in fact, they're probably much better options. And this is the key point. In unsupervised learning we don't have a lot to work with, there are no labels. We just have the input space and in many cases a distance or similarity function. But there's quite a lot of flexibility in how we choose these and it's important to choose them well. Next time we'll look at some other possibilities for ChemCam data. 